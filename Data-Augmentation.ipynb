{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms labels in form suitable for CNN\n",
    "def label_trafo(labels, num_labels):\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        tmp = np.zeros((num_labels))\n",
    "        tmp[int(label)] = 1\n",
    "        new_labels.append(tmp)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrafficSigns(rootpath, IMG_SIZE, min_img_size=32, classes=np.arange(0,43), img_format='png', label_trafo_=True, label_num=43):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training' and image size\n",
    "    Returns:   trainingdata'''\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # loop over all 42 classes\n",
    "    for c in classes:\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        k = 0\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            #ignore first row in csv file\n",
    "            if k == 0:\n",
    "                pass\n",
    "            else:\n",
    "                #check if img has at least min_size\n",
    "                if int(row[1]) < min_img_size:\n",
    "                    pass\n",
    "                else:\n",
    "                    if img_format == 'ppm':\n",
    "                        #read ppm format\n",
    "                        features.append(cv2.resize(plt.imread(prefix + row[0]), (IMG_SIZE,IMG_SIZE)))\n",
    "                        labels.append(int(row[7]))\n",
    "                    elif img_format == 'png':\n",
    "                        #read png format\n",
    "                        features.append(cv2.resize(plt.imread(prefix + row[0][0:-4]+'.png'), (IMG_SIZE,IMG_SIZE)))\n",
    "                        labels.append(int(row[7]))\n",
    "                    else:\n",
    "                        pass\n",
    "                        \n",
    "            k += 1\n",
    "        gtFile.close()\n",
    "    #transform labels\n",
    "    if label_trafo_ == True:\n",
    "        labels = label_trafo(labels, label_num)    \n",
    "    features = np.reshape(features, (-1, IMG_SIZE, IMG_SIZE, 3))\n",
    "    return [features, labels]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate directory\n",
    "os.mkdir('New_Augmented_Images/')\n",
    "for c in range(0,43):\n",
    "    os.mkdir('New_Augmented_Images/'+'Class'+str(c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=shift, height_shift_range=shift, shear_range=0.2, zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#number of desired images per class\n",
    "final_img_num = 2500\n",
    "save_format = '.ppm'\n",
    "read_format = 'ppm'\n",
    "#augment images\n",
    "for c in range(0,43):\n",
    "    \n",
    "    X, y = readTrafficSigns(rootpath='GTSRB/Final_Training/Images', IMG_SIZE=32, min_img_size=32, classes=[c], img_format=read_format)\n",
    "    print(X.shape)\n",
    "    \n",
    "    X = X.astype('float32')\n",
    "\n",
    "    # add arrays to big training array, same for labels\n",
    "    if c == 0:\n",
    "        features = X\n",
    "        labels = np.array(y)\n",
    "    else:\n",
    "        features = np.concatenate((features, X), axis=0)\n",
    "        labels = np.concatenate((labels, y), axis=0)\n",
    "    datagen.fit(X)\n",
    "    # save original images\n",
    "    k = 0\n",
    "    for img in X:\n",
    "        cv2.imwrite('New_Augmented_Images/'+'Class'+str(c)+'/orig'+str(k)+save_format,cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        k += 1\n",
    "    img_num = X.shape[0]\n",
    "    #augmentation step\n",
    "    k = 0\n",
    "    for X_batch, y_batch in datagen.flow(X, y, batch_size=32):#, save_to_dir='New_Augmented_Images/'+'Class'+str(c), save_prefix='aug', save_format='ppm'):\n",
    "        # check if enough images were generated\n",
    "        if img_num > final_img_num:\n",
    "            break\n",
    "        # create a grid of 3x3 images\n",
    "        if k == 0:\n",
    "            for i in range(0, 9):\n",
    "                plt.subplot(330 + 1 + i)\n",
    "                plt.imshow(X_batch[i].reshape(X.shape[1], X.shape[2], 3).astype(np.uint8), cmap=plt.get_cmap('gray'))\n",
    "            # show the plot\n",
    "            plt.show()\n",
    "        # save image\n",
    "        for img in X_batch:\n",
    "            cv2.imwrite('New_Augmented_Images/'+'Class'+str(c)+'/aug'+str(k)+save_format,cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            k += 1\n",
    "        img_num += X_batch.shape[0]\n",
    "        # add to big training array\n",
    "        features = np.concatenate((features, X_batch), axis=0)\n",
    "        labels = np.concatenate((labels, y_batch), axis=0)\n",
    "np.save(\"aug_features_32x32\", features)\n",
    "np.save(\"aug_labels_32x32\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For fixed Training set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"train_data.npy\")*255\n",
    "y_train = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=shift, height_shift_range=shift, shear_range=0.2, zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = []\n",
    "class_labels = []\n",
    "for i in range(0,43):\n",
    "    class_features.append([])\n",
    "    class_labels.append([])\n",
    "\n",
    "for i, label in enumerate(y_train):\n",
    "    class_labels[int(np.argmax(label))].append(label)\n",
    "    class_features[int(np.argmax(label))].append(X_train[i])\n",
    "X_train = None\n",
    "y_train = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate directory\n",
    "os.mkdir('New_Augmented_Images/')\n",
    "for c in range(0,43):\n",
    "    os.mkdir('New_Augmented_Images/'+'Class'+str(c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#number of desired images per class\n",
    "final_img_num = 4000\n",
    "save_format = '.ppm'\n",
    "# scaling factor for the number of images\n",
    "factor = 1\n",
    "add_images = 1000\n",
    "\n",
    "#augment images\n",
    "\n",
    "# store original images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for c in range(0,43):\n",
    "for c in [7,20,29]:\n",
    "    if c == 0:\n",
    "        pass\n",
    "        #features = np.array(class_features[c])\n",
    "        #labels = np.array(class_labels[c])\n",
    "    else:\n",
    "        pass\n",
    "        #features = np.concatenate((features, np.array(class_features[c])), axis=0)\n",
    "        #labels = np.concatenate((labels, np.array(class_labels[c])), axis=0)\n",
    "    X = np.array(class_features[c]).astype('float32')\n",
    "    y = np.array(class_labels[c])\n",
    "    datagen.fit(X)\n",
    "    # save original images\n",
    "    k = 0\n",
    "    for img in X:\n",
    "        #cv2.imwrite('New_Augmented_Images/'+'Class'+str(c)+'/orig'+str(k)+save_format,cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        k += 1\n",
    "    img_num = X.shape[0]\n",
    "    #img_num = 0\n",
    "    orig_num = X.shape[0]\n",
    "    #augmentation step\n",
    "    k = 0\n",
    "    for X_batch, y_batch in datagen.flow(X, y, batch_size=32):#, save_to_dir='New_Augmented_Images/'+'Class'+str(c), save_prefix='aug', save_format='ppm'):\n",
    "        \n",
    "        if c == 7 and k == 0:\n",
    "            features = X_batch\n",
    "            labels = y_batch\n",
    "        else:\n",
    "            # add to big training array\n",
    "            features = np.concatenate((features, X_batch), axis=0)\n",
    "            labels = np.concatenate((labels, y_batch), axis=0)\n",
    "            \n",
    "        # create a grid of 3x3 images\n",
    "        if k == 0:\n",
    "            for i in range(0, 9):\n",
    "                plt.subplot(330 + 1 + i)\n",
    "                plt.imshow(X_batch[i].reshape(X.shape[1], X.shape[2], 3).astype(np.uint8), cmap=plt.get_cmap('gray'))\n",
    "            # show the plot\n",
    "            print(y_batch[0])\n",
    "            plt.show()\n",
    "            \n",
    "        # check if enough images were generated    \n",
    "        if img_num > final_img_num:\n",
    "            break\n",
    "        if img_num > add_images + orig_num:\n",
    "            break    \n",
    "        \n",
    "        # save image\n",
    "        for img in X_batch:\n",
    "            #cv2.imwrite('New_Augmented_Images/'+'Class'+str(c)+'/aug'+str(k)+save_format,cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            k += 1\n",
    "        img_num += X_batch.shape[0]\n",
    "        # empty memory\n",
    "        class_features[c] = None\n",
    "    print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_data_augmented_low+1000\", features/255)\n",
    "np.save(\"train_labels_augmented_low+1000\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize augmentation\n",
    "X_train = np.load(\"train_data.npy\")*255\n",
    "y_train = np.load('train_labels.npy')\n",
    "\n",
    "class_features = []\n",
    "class_labels = []\n",
    "for i in range(0,43):\n",
    "    class_features.append([])\n",
    "    class_labels.append([])\n",
    "\n",
    "for i, label in enumerate(y_train):\n",
    "    class_labels[int(np.argmax(label))].append(label)\n",
    "    class_features[int(np.argmax(label))].append(X_train[i])\n",
    "X_train = None\n",
    "y_train = None    \n",
    "\n",
    "# define data preparation\n",
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=shift, height_shift_range=shift, shear_range=0.2, zoom_range=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(5, 1), constrained_layout=True)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "#plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "axs[0].imshow(class_features[14][0].astype('uint8'))\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "\n",
    "k = 1\n",
    "for X_batch, y_batch in datagen.flow(np.reshape(class_features[14][0], (1,48,48,3)), np.reshape(class_labels[0][0],(1,43)), batch_size=9):\n",
    "    axs[k].imshow(X_batch[0].astype('uint8'))\n",
    "    #axs[k].imshow(class_features[14][0].astype('uint8'))\n",
    "    axs[k].set_xticks([])\n",
    "    axs[k].set_yticks([])\n",
    "    if k == axs.shape[0]-1:\n",
    "        break\n",
    "    k += 1\n",
    "\n",
    "plt.savefig('augmentation.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pretrained model with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten, MaxPooling2D, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('train_data.npy')\n",
    "y_train = np.load('train_labels.npy')\n",
    "#X_val = np.load('val_data.npy')\n",
    "#y_val = np.load('val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.load('train_data_augmented_500_per_class.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_aug_train = np.concatenate((np.load('train_data_augmented_low+1000.npy'),np.load('train_data.npy')), axis=0)\n",
    "y_aug_train = np.concatenate((np.load('train_labels_augmented_low+1000.npy'), np.load('train_labels.npy')), axis=0)\n",
    "\n",
    "#X_aug_train = np.concatenate((np.load('train_data_augmented_500_per_class.npy'),np.load('train_data.npy')), axis=0)\n",
    "#y_aug_train = np.concatenate((np.load('train_labels_augmented_500_per_class.npy'), np.load('train_labels.npy')), axis=0)\n",
    "\n",
    "\n",
    "# split test set into real test set and small validation set\n",
    "X_aug_train, X_aug_val, y_aug_train, y_aug_val = train_test_split(X_aug_train, y_aug_train, test_size=0.08, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('train_data_augmented_500_per_class+train_data', X_aug_train)\n",
    "#np.save('train_labels_augmented_500_per_class+train_labels', y_aug_train)\n",
    "#np.save('val_data_augmented_500_per_class+train_data', X_aug_val)\n",
    "#np.save('val_labels_augmented_500_per_class+train_labels', y_aug_val)\n",
    "\n",
    "#np.save('train_data_augmented_reproduce+train_data', X_aug_train)\n",
    "#np.save('train_labels_augmented_reproduce+train_labels', y_aug_train)\n",
    "#np.save('val_data_augmented_reproduce+train_data', X_aug_val)\n",
    "#np.save('val_labels_augmented_reproduce+train_labels', y_aug_val)\n",
    "\n",
    "#np.save('train_data_augmented_+750_2000max+train_data', X_aug_train)\n",
    "#np.save('train_labels_augmented_+750_2000max+train_labels', y_aug_train)\n",
    "#np.save('val_data_augmented_+750_2000max+train_data', X_aug_val)\n",
    "#np.save('val_labels_augmented_+750_2000max+train_labels', y_aug_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_aug_train = np.load('train_data_augmented_500_per_class.npy')\n",
    "#y_aug_train = np.load('train_labels_augmented_500_per_class.npy')\n",
    "\n",
    "X_aug_train = np.load('train_data_augmented_reproduce_class.npy')\n",
    "y_aug_train = np.load('train_labels_augmented_reproduce_class.npy')\n",
    "\n",
    "\n",
    "X_aug_train, X_aug_val, y_aug_train, y_aug_val = train_test_split(X_aug_train, y_aug_train, test_size=0.08, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.models.load_model('Optimization Results/Standard Trained Model/CNN_16_96_128_epochs_5_relu_RMSprop_categorical_crossentropy_padding_same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36669 samples, validate on 3189 samples\n",
      "Epoch 1/1\n",
      "36669/36669 [==============================] - 7s 191us/step - loss: 0.0426 - accuracy: 0.9888 - val_loss: 0.0181 - val_accuracy: 0.9972\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "status = model_1.fit(X_aug_train, y_aug_train, batch_size=64, epochs=n_epochs, validation_data=(X_aug_val,y_aug_val))#, callbacks=[tensorboard])\n",
    "#status = model_1.fit(X_train, y_train, batch_size=64, epochs=n_epochs, validation_data=(X_val,y_val))\n",
    "NAME = \"CNN_16_96_128_relu_RMSprop_categorical_crossentropy_padding_same_augmented_low+1000\"\n",
    "\n",
    "path = 'Optimization Results/'+NAME\n",
    "\n",
    "model_1.save(path)\n",
    "results = np.zeros((3,n_epochs))\n",
    "results[0::] = (np.array(status.epoch)+1)\n",
    "results[1::] = np.array(status.history['val_loss'])\n",
    "results[2::] = np.array(status.history['val_accuracy'])\n",
    "#np.save(path, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
